{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "89c25c59-8025-456d-be3b-a4024e4724e6",
   "metadata": {},
   "source": [
    "I want notes on gradient boosting, here are the points\n",
    "\n",
    "* prediction is a sum of small not too complex predictions\n",
    "* Step 0 is defining the loss factor (needs to be differentiable? why?)\n",
    "* Step 1: Start with an extremely weak learner. f1x can jus be the mean of the data\n",
    "* Step 2: Key step. We will compute r1i (Gradient which is the derivative of the loss function with respect to the prediction we have right now. We do this for all data points and store the gradient in the r variables (What is a gradient?)\n",
    "* Step 3: Fit the new weak learner"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
