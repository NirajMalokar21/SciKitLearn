{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "36035647-e26c-46f2-83e4-df789792dfe2",
   "metadata": {},
   "source": [
    "# What is classification?\n",
    "\n",
    "#### Process of categorizing a given set of data into classes\n",
    "#### Can be performed on both structured and unstructured data\n",
    "#### Starts with predicting the class ofa  given data points.\n",
    "#### Classes are referred to as targets, or labels\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19fd15b7-0e55-4613-92a3-6d49449bd1d1",
   "metadata": {},
   "source": [
    "### Perceptron is single layered network in a neural network\n",
    "\n",
    "#### We will use the OR Gate for example\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9a036ddd-e369-4741-9199-229df6cb9f5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0],\n",
       "       [0, 1],\n",
       "       [1, 0],\n",
       "       [1, 1]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np \n",
    "x = np.array([[0,0], [0, 1], [1, 0], [1, 1]])\n",
    "y = np.array([0, 1, 1, 1]) \n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "49a15f6b-1764-45cd-99c5-ddd1714531f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 1, 1])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d1ba6b6-a295-4a3f-9db8-315ed931cec0",
   "metadata": {},
   "source": [
    "#### Weight vector\n",
    "\n",
    "* It is a vector that assigns importance to each input feature\n",
    "* Since each input is a 2 element vector, the weights are also 2-element: [w1, w2]\n",
    "* We are treating both inputs equally since both are 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1c5cec65-3288-4fc4-8514-11afb6c3bb39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w = np.array([1, 1])\n",
    "w"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c526bbdc-a2cd-4423-8440-5327a61b632d",
   "metadata": {},
   "source": [
    "#### Bias\n",
    "\n",
    "* Bias shifts the decision boundary\n",
    "* It is like a default outpt before seeing any input - helps the model learn functions that dont pass through the origin\n",
    "* Moves the treshold so that only [0, 0] produces a 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9ffa671b-fd8e-418e-bc66-7ba966064d6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "b = -0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9d48e217-9e75-4d07-8933-9b9c4eff65be",
   "metadata": {},
   "outputs": [],
   "source": [
    "def activation(z):\n",
    "    if z >= 0:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "642ef7e0-6946-4c38-b715-0f3ebbb4ed70",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = []\n",
    "for a in x:\n",
    "    y_hat = np.dot(a,w)+b\n",
    "    pred.append(activation(y_hat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8bc53e75-d2b2-443a-8c3c-aad7bfc97c4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 1, 1]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6ba7bf7-3d2c-4fa8-94ab-bad5e9eb4176",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Perceptron Learning\n",
    "\n",
    "1) Concept: Train weights over epochs, and iterate prediction error back to the perceptron for each epoch\n",
    "2) During error propogation process, we will make changes in our weight values till the time our perceptron makes accurate predictions\n",
    "3) Weight(new) = Weight(old) - Learning_rate * (Gradient of error with respect to weight)\n",
    "4) Error = Output - Predicted_Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dec18598-4500-431e-b8a9-206bea6c9fb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "844a0e43-992a-4665-adbc-ea31d89eccdb",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Epochs are the of times you train over the full dataset\n",
    "Alpha is the learning rate, higher = faster learning, but riskier (overshooting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8e1e3fc9-e23f-4ecb-9c34-00db8be5d0a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 4\n",
    "alpha = 0.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5777c50a-4427-4bd6-a10e-84223d29366d",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial weights:\n",
      "w0:  0.9321873169825927  w1:  0.44509219729200633  w2:  0.09739391520545049\n"
     ]
    }
   ],
   "source": [
    "w0 = np.random.random() \n",
    "w1 = np.random.random()  \n",
    "w2 = np.random.random() \n",
    "print(\"Initial weights:\")\n",
    "print(\"w0: \", w0, \" w1: \", w1, \" w2: \", w2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3787fc82-5893-4cda-8a6d-ade3ba358303",
   "metadata": {},
   "source": [
    "These store weight updates (deltas). Initially set to 1, but will be recalculated every training step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "01b7496b-83ef-425f-8b44-e7452e2d3060",
   "metadata": {},
   "outputs": [],
   "source": [
    "del_w0 = 1\n",
    "del_w2 = 1\n",
    "del_w1 = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "34d3b6dc-d74d-40b1-9af0-efffd44554ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_temp = [[0, 0, 0], [0, 0, 1], [0, 1, 0], [1, 0, 0], [0, 1, 1], [1, 0, 1], [1, 1, 0], [1, 1, 1]]\n",
    "train_data = np.asarray(train_data_temp)\n",
    "op = np.array([0, 1, 1, 1, 1, 1, 1, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d0b561e3-93d7-4b51-b56b-30e6cf38132d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0],\n",
       "       [0, 0, 1],\n",
       "       [0, 1, 0],\n",
       "       [1, 0, 0],\n",
       "       [0, 1, 1],\n",
       "       [1, 0, 1],\n",
       "       [1, 1, 0],\n",
       "       [1, 1, 1]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "faebbf5f-154e-4638-98da-ffe1e9ed3cc4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 1, 1, 1, 1, 1, 1])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "op"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbaf6af0-ae0b-432e-a333-78a8499c6e27",
   "metadata": {},
   "source": [
    "y = (x*w) + b"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc33398c-a0f8-4b37-929f-fd7ccce1decb",
   "metadata": {},
   "source": [
    "#### This function does the following:\n",
    "1) Initializes the bias\n",
    "2) Training Loop:\n",
    "   \n",
    "       a) Outer loop repeats training for epochs times\n",
    "       b) Inner loop goes through each training sample x and learns from it\n",
    "\n",
    "   \n",
    "4) y_hat is the prediction. Linear combination of inputs and weights, like a raw score before activation\n",
    "5) Activate function: If weighted sum > 0, predict 1, else predict 0\n",
    "6) This function turns the continuous score y_hat into a discrete classification decision\n",
    "7) Error is calculated using the correct label op[j] and predicted label act\n",
    "8) Then it uses the Perceptron Learning rule\n",
    "   \n",
    "       a) delta_w = alpha * input * error\n",
    "       b) if error = 0, dont change anything\n",
    "       c) if error = +1 (prediction too low), increase weight\n",
    "       d) if error = -1 (prediction too high), decrease weight\n",
    "\n",
    "   \n",
    "10) Then we update the weights using w = w + del_w\n",
    "11) This is the core of training, slowly nudging the weights toward better predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9cb3777b-fffc-4ba8-9c63-614cd7b75e8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Final Weights = \n",
      "w0:  0.9321873169825927  w1:  0.44509219729200633  w2:  0.09739391520545049\n"
     ]
    }
   ],
   "source": [
    "bias = 0 # Can also be trained like weights\n",
    "for i in range(epochs):\n",
    "    j = 0\n",
    "    for x in train_data: \n",
    "        y_hat = w0*x[0] + w1*x[1] + w2*x[2] + bias \n",
    "\n",
    "        if(y_hat > 0):\n",
    "            act = 1\n",
    "        else: \n",
    "            act = 0\n",
    "        err = op[j] - act\n",
    "\n",
    "        del_w0 = alpha*x[0]*err \n",
    "        del_w1 = alpha*x[1]*err\n",
    "        del_w2 = alpha*x[2]*err\n",
    "\n",
    "        w0 = w0 + del_w0\n",
    "        w1 = w1 + del_w1\n",
    "        w2 = w2 + del_w2\n",
    "\n",
    "        j = j+1\n",
    "        #print(\"epoch: \", i+1, \" error: \", err)\n",
    "        #print(del_w0, del_w1, del_w2)\n",
    "print(\"\\nFinal Weights = \")\n",
    "print(\"w0: \", w0, \" w1: \", w1, \" w2: \", w2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa0b798e-083b-4547-b44c-8c4d4fad294e",
   "metadata": {},
   "source": [
    "--- \n",
    "\n",
    "\n",
    "# Types of Classification\n",
    "\n",
    "## Binary Classification\n",
    "\n",
    "### Requires two classes, one in normal state, other in aberrant state\n",
    "\n",
    "## MultiClass Classification\n",
    "\n",
    "### Data points are grouped into several well known classes\n",
    "\n",
    "## MultiLabeled Classification\n",
    "\n",
    "### Features more then two class labels\n",
    "\n",
    "## Imbalance Classification\n",
    "\n",
    "### Each class has different distribution\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be55386a-7195-4001-8854-15bdf5200257",
   "metadata": {},
   "source": [
    "--- \n",
    "\n",
    "# Learner Type Terminology\n",
    "\n",
    "## Lazy Learner\n",
    "\n",
    "### Lazy learner delays the generalization of training data until a query is made to the system. \n",
    "#### Example: KNN\n",
    "\n",
    "## Eager Learner\n",
    "\n",
    "### Before obtaining a test dataset, eager learners build a classification model using a training dataset. \n",
    "#### Example: ANN, Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "135f10e8-f962-4ef4-8c17-949cc7bd436f",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
